 <!DOCTYPE html>
<html lang="en">
<head>
	<title>Quantum Computing</title>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="bootstrap/bootstrap.min.css">
	<script src="jquery/jquery.min.js"></script>
	<script src="bootstrap/bootstrap.min.js"></script>
	<script src="latex.js"></script>
	<script src="formulas.js"></script>
	<script src="architecture.js"></script>
	<script src="algorithms.js"></script>
	<link rel="stylesheet" type="text/css" href="style.css">
</head>

<body>
	<canvas id="background"></canvas>
	<script src="drops.js"></script>
	
	<div style="margin-left:10%; margin-right:10%; padding-left:5%; padding-right:5%;" class="main even">
	
	<!-- Content nav -->
		<div id="holder" class="fixeddiv"> <div class="row placeholders">
			<br>
			<div href="#deutsch" class="scroller" align="center">
				<div class="col-xs-6 col-sm-4 placeholder" align="center">
					<img src="media/algo1.jpg" 
						class="smallexpandable img-circle" 
						alt="Generic placeholder thumbnail">
					<h4>Deutsch's Algorithm</h4>
				</div>
			</div>
			<div  href="#title2" class="scroller" align="center">
				<div class="col-xs-6 col-sm-4 placeholder" align="center">
					<img src="media/algo2.jpg" 
						class="smallexpandable  img-circle"  
						alt="Generic placeholder thumbnail">
					<h4>Grover's Search Algorithm</h4>
				</div>
			</div>
			<div href="#title3" class="scroller" align="center">
				<div class="col-xs-6 col-sm-4 placeholder" align="center">
					<img src="media/algo2.png" 
						class="smallexpandable img-circle" 
						alt="Generic placeholder thumbnail">
					<h4>HHL<br> Algorithm</h4>
				</div>
			</div>
		</div> </div>

	</div>
	<div style="margin-left:10%; margin-right:10%; padding-left:5%; padding-right:5%" class="main odd">
	
	<!-- Content -->
		<h2 name="deutsch" id="deutsch"><br>Deutsch's Algorithm</h2> <!--Quantum book exact citation-->
		<br>

		<p> Quantum algorithms can be developed on top of a framework based on combining quantum gates. We can summarise the whole process in the following steps: </p>
		<ul>
			<li> The system starts with bits in a classical state. </li>
			<li> From there, the system is put into a superposition. </li>
			<li> The state is transformed using unitary operations (i.e. quantum gates). </li>
			<li> Measure the qubits, forcing them to collapse in a state.</li>
		</ul>

		<p> Notice all algorithms are probabilistic ones, not deterministic. That means, we are not guaranteed that they will work for 100% of the cases, but we do have a high probability of success. </p> 

		<h3> The problem </h3> <!-- http://www.cs.xu.edu/~kinne/quantum/deutche.html -->

		<p id="dt1"> Suppose there is a function <i>f</i> that maps from <span id="adiFormula16"></span> to <span id="adiFormula17"></span>. We wish to know whether the function is <i>injective</i> or not (i.e. <span id="adiFormula18"></span> is not equal <span id="adiFormula19"></span>). Opposing to the classic context, 
		one can not examine the function on different results. The main idea is to consider the gate <i>U</i>
		as a matrix function operator (to be visualised as a gate) applying the function f to the given
		inputs.</p>

		</p> The problem could be solved by evaluating f(0) <span id="tensor1"></span> f(1). The <i><b>XOR</b></i> function is the direct equivalent of asking whether f is an injection. Even though the function is evaluated twice in a classical context, the quantum context allows us to evaluate it only once. </p>
	
		<h3> Breaking down the problem </h3>

		<p>At the moment we know we want to obtain a superstate that will be extracted after measurement to f(0) <span id="tensor2"></span> f(1). We only need a superstate that will be transfered to this particular point. The input is 0 and 1 along with any combination. </p>

		<p id="dt2"> Firstly, we have to keep in mind that we can process two states simultaneously. We need a matrix(gate) that gives us a state that has an equal probability to be measured as a 0 or 1. We can observe that the <i><b>Hadamard</b></i> gate gives us a good beahaviour:</p> 

		<p> </p>

		<p id="dt3"> Looking over the effect of the Hammond gate over the 0 and 1 states, we can observe that both bits will be driven to balanced superstates. Also, the products differ only by a sign. </p>
		<p id="dt4"></p>

		<p> </p>

		<p>At this moment, we have all the information: the input, the desired output, some means of transformations to balanced superstates, and finally, the application of function f. </p>

		<br>
		<h3>Putting the bits together </h3>

		<p> We will examine the circuit proposed by <b><i>David Deutsch</i></b> by looking at each step on the <i>"pipeline"</i>. </p>

		<center>
		<img src="media/algop1.png" width=50%></img>
		</center>

		<p id="dt5"> The pipelining mechanism can be expressed strictly in terms of matrices. We have 2 inputs that will be composed using the tensor product. Afterwards, each pair of binary gates will be multiplied (tensor product) so that we keep applying each matrix operator to the combined state. (4-by-1 matrix) Finally, the upper result will be measured. </p>

		<p id="dt_state1"> Let us look at the involved states step by step. Firstly, our state will be the product of the given input qubits.</p>

		<p id="dt_state2"> In the first step, we need to apply the <b><i>Hadamard</i></b> transformation to each of the matrices. Observe that it distributes the probabilities evenly. </p>
		
		<p id="dt_state_gen"> Observe the effect of function f over the state we have obtained. Let us study the effect of function f on the element <span id="adiFormula1"></span>. We only need to apply the tensor product of the current value with the function application. More concisely,
		the function will look just as <span id="adiFormula2"></span>.</p>

		<p id="dt_state3"> Applying the property to both elements will give two comopsitions similar to the former one. Finally, we need just analyse the outcome of the function in each case.</p>
		<p id="dt_state4"></p>
		<p id="dt_state5"> Remember that each gate is reversible, so <b><i>Hadamard</i></b> matrix should put its resulting state to the original input. Therefore, reapplying the <b><i>Hadamard</i></b> matrix back will drive us into one of the initial states (0 or 1). We are particularly interested in the 0 as it will multiply to a null term after measurement. </p>
		<p id="dt_state6"></p>

		<p> Finally, measuring the top bit will give either 0, or another result. In the case the result is 0, we know that f is a constant function. </p>

		<div align="center" href="#holder" class="scroller">
			<img src="media/up.png" width=25></img>
			<p> Go to top </p>
		</div>
	</div>

	<div style="margin-left:10%; margin-right:10%; padding-left:5%; padding-right:5%" class="main even">	
		<h2 name="title2" id="title2"><br>Grover's Search Algorithm</h2> <!--Quantum book exact citation-->
		<br>

		<p> <b><i>Grover’s Search</i></b> is an algorithm based on searching an element in a list, faster than just going through all the elements and stop at some point. Using a naive brute force strategy of just taking element by element and break at some point when we find an answer will result to an average of <span id="adiFormula9"></span> operations per searching. <b><i>Grover’s Search Algorithm</i></b> aims for <span id="ini1"></span> such operations. </p>
		
		<p> Imagine that you are given a function <span id="gg1"></span> and you are assured that there exists exactly one binary string <span id="adiFormula5"></span> such that <span id="adiFormula7"></span> if <span id="ini2"></span> and <span id="adiFormula8"></span> otherwise. <i>f</i> will be given to us as the unitary matrix <span id="adiFormula6"></span> that takes <span id="ini3"></span>. </p> 
		<p id="gg2"> In terms of matrices this becomes: </p>
		
		<p> The states are:</p>
		<p id="gg3"></p>
		<p id="gg4"></p>
		<p id="gg5"></p>
		
		<br><br>

		<p> <i><b>Grover’s search algorithm</b></i> uses two tricks. The first, called <i><b>phase inversion </b></i>, changes the phase of the desired state. It works as follows. Take <span id="ini6"></span> and place the bottom qubit in the superposition state: </p>
		
		<p id="ini4"></p>
		
		<p id="ini5"> In terms of matrices, this becomes:</p>
		
		<br><br>

		<p> Since both <span id="ini7"></span> and <i>H</i> are unitary operations, it is obvious that <i><b>phase inversion</b></i> is also a unitary operation. </p>
		
		<p id="gg6"> The states are: </p>
		<p id="gg7"></p>
		<p id="gg8"></p>
		<p id="gg9"></p>

		<br><br>

		<p> What we need now is a way of boosting the phase separation of the desired binary string from the other binary strings. The second trick is called <i><b>inversion about the mean</b></i>. Basically, we are inverting each element around the average (the mean of all elements). </p>
		
		<p> <b><i>Example:</i></b> Consider a sequence of integers <span id="adiFormula10"></span>. The average is <span id="adiFormula11"></span>. Inverting a number around the average is equivalent with adding the difference between the average and the number to the given mean. That is each element <span id="adiFormula12"></span> becomes <span id="adiFormula13"></span>. (<span id="adiFormula14"></span> becomes <span id="adiFormula15"></span>).</p>
		
		<p id="gg10"> Let us write this in terms of matrices. Consider the vector <span id="adiFormula3"></span> and the matrix:</p>
		
		<p> It is easy to see that <i>A</i> is a matrix that finds the average of a sequence: <span id="adiFormula4"></span> (this is for the given vector and <i>n = 5</i>). </p>
		
		<p id="gg11"> Starting from this basic matrix, we can construct now the <i><b>“inversion about the mean matrix”</b></i>:</p>
		
		<p> If the previous matrix transformed each element into the average, the formed directly apply the second trick of <i><b>Grover’s search algorithm</b></i>. </p>
		
	    <p> Doing the inversion about the mean matrix only once is not enough in order to have a proper answer (as it is said above, the purpose of it is just boosting the phase separation). </p>
	    
	    <p> <i><b>Grover’s algorithm</b></i> consists of repeatedly applying the boosting process a sufficient amount of times. Before discussing the exact complexity and number of steps, let’s analyze the final scheme of <b><i>Grover’s algorithm</i></b>: </p>
	    
	    <ul>
			<li> <b><i>Step 1:</i></b>  Start with a state <span id="ini8"></span> </li>
			<li> <b><i>Step 2:</i></b> Apply <span id="ini9"></span> </li>
			<li> <b><i>Step 3:</i></b> Repeat T times (we will see who T is): </li>
			<ul>
			    <li><b><i>Step 3a:</i></b>  Apply the phase inversion operation (first trick) </li>
			    <li><b><i>Step 3b:</i></b> Apply the inversion about the mean operation (second trick) </li>
			</ul>
			<li> <b><i>Step 4:</i></b> Measure the qubits. </li>
		</ul>
		
		<p> The final question is who is <i>T</i>? (or how many times do we need to apply step 3). The answer is <span id="ini10"></span>. If you do it more than that, the process will <i><b>“overcook”</b></i>. The proof for this fact use geometry representation which is beyond our current goal. </p>

		<div align="center" href="#holder" class="scroller">
			<img src="media/up.png" width=25></img>
			<p> Go to top</div>
	</div>
	
	<div style="margin-bottom: 50px; margin-left:10%; margin-right:10%; padding-left:5%; padding-right:5%" class="main odd">
		<h2 name="title3" id="title3"><br>Harrow-Hasidim-Lloyd Algorithm</h2>
		<br>

		<p> We have now a general idea about the physical implementation, scaleability and a real-world
		theoretical example. The next step is to try to dive into the intuition behind a more complex algorithm. </p>

		<p id="hhl1"> The problem is solving a system of linear equations. In order for us to be able to model it in the quantum context, we will put it in the following form: </p>
		<br><br>

		<p id="hhl2"> The matrix <i>A</i> and the vector <i>b</i> are known and we want to find the vector <i>x</i>. In the classical context this problem is well-known and its complexity is polynomial. Our main goal is to find the inverse of the matrix <i>A</i>. </p>
		<br><br>

		<p> The most well known algorithm is Gaussian elimination. The algorithms reduces the augmented matrix each line of the matrix in row echelon form. Each transition between two matrices represents adding up 2 equations. Finally, we get each element of the solution vector from bottom to top. </p>

		<p> The complexity analysis is straight forward, we iterate through <i>N</i> lines, reducing <i>O(N)</i> in <i>O(N)</i> places. It is worth mentioning that in a sparse matrix(meaning the number of non-zero element in each row is much smaller than the number of element in that row), there are algorithms that run in O(N^2 log N). </p>

		<p id="hhl3">The intuitive advantage of solving the exact same problem in the quantum setting is relying on the fact that we can process multiple states at a moment. Supposing we can successfully represent a state of size O(N) as a set of qubits, the number of necessary qubits is O(log N).</p>
		<br><br>

		<p> Supposing we work with an exponential number of states, we can not naturally parse the computed result as this will slow the total speed of our algorithm from polynomial to exponential. Fortunately, we can get sufficient information about the properties of the resulting state from the eigenvalue of the observable. As an example if one has one terrabit of data in the output vector, we can encode the result in around 40 qubits. On the one hand, listing the resulting data will take the original size.(i.e. listing one terra of data). On the other hand, measuring the properties of the observable will give us the possibility to look at particular properties(i.e. eigenvalues) that we are interested in. </p>

		<!-- Caz pt non-Hamiltoniana -->

		<br>
		<h3> Simulating Hamiltonians </h3>

		<p>From the fact that the matrix A is Hermitian, we know that <span id="hhl4"></span>, therefore A is reversible. Furthermore, the sparse Hamiltionian algorithm is applicable in this context. <sup>[paper]</sup> </p>

		<div class="well well-sm wellodd" id="hhl5">
			We denote an <b><i>evolution</i></b> the physical transformations applied over a closed quantum system on a fixed amount of time without any observable interaction. 
		</div>

		<p><br> A Hamiltonian evolution can be written as <span id="hhl7"></span>, where matrix A is computed with an relative error denoted as <span id="hhl8"></span>. An intuitive reasoning is that there is a mapping from the matrix U to the complex space of vectors with modulus of 1. Having a Hamiltonian decomposed as a sum <span id="hhl6"></span>, we can rewrite the evolution relative to each component of U at the moment t: <span id="hhl9"></span>. Furthermore, Dominic W. Berry, Graeme Ahokas, Richard Cleve and Barry C. Sanders propose a logarithmic complexity method for sparse matrices of finding a series of form <span id="hhl7p"></span> which simulates the previous evolution bounded by the given error. <sup>[paper]</sup>  </p> <!-- http://arxiv.org/pdf/quant-ph/0508139v2.pdf -->

		<p> The details of the method are not as straight forward as the previous algorithms, but we want to empathise its purpose: </p>

		<div class="well well-sm wellodd">We can simulate the evolution of a transformation over a small period of time with a fixed error in a complexity squared proportional to the sparsity of the matrix and logaritmically proportional with its size. </div>

		<br>
		<h3>Finding the inverse</h3>

		<p> We know from linear algebra that if a matrix <i>A</i> is diagonalizable, we can find it's inverse in a simple way.
		<br> 
		<span id="hermite1"></span>. Since <i>A</i> is diagonalizable, then there exists an invertible matrix <i>U</i> such that <span id="invertible"></span>, where <span id="lambdas"></span> are the eigenvalues of <i>A</i>. We get <span id="inverse"></span>. Hence, <span id="inverse2"></span>.

		<br>
		<h3>Application of quantum phase algorithm</h3>

		<p> Having defined the transformations above, we can see that the Hamiltonian simulation scales over the whole sum. The paper [paper2] determines the eigenvalues using the momentum simlarly to the use of the evolution over time. Intuitively, the momentum resembles to the classical one, therefore applying the transformation over it should yeld some intrinsec property of the matrix. This property has been demonstrated to be(in the same paper) the set of eigenvalues. </p> 

		<p>Let's denote: <span id="rr1"></span> Then: <span id="rr2"></span>. </p>

		<p>Appling <span id="rr3"></span> over the value <span id="rr4"></span> gives us, <span id="rr5"></span> where <span id="rr6"></span> are the eigenvalues of A and  <span id="rr7"></span> is decomposed in terms of the basis.</p>

		<p> Applying the transformation once will give us the eigenvalues. By [paper3], each eigenvalue will be introduced in a similar way, obtaining the result: <span id="rr8"></span> </p>

		<p> If we apply the phase algorithm transformation we can compress the decomposition of <span id="rr7b"></span>, getting the zero qubit on right hand side - <span id="rr0"></span> - and then <span id="rr9"></span>.</p>

		<p> Shortly, applying the phase algorithm in the right way will give us the eigenvalues and eigenvectors. Appling its inverse after rewriting the evolution for each member of the sum will give us the inverse of the matrix.</p>

		<h3> Property measurement </h3>

		<p id="mes"> As we mentioned initally, even if we obtained the matrix, we would like to measure some of its "properties". Let a property be an observable M, then we can apply: </p>


		<div align="center" href="#holder" class="scroller">
			<img src="media/up.png" width=25></img>
			<p> Go to top </p>
		</div>

	<script src="scroll.js"></script>
	<script>
		parser.staticParse(algoFormulas.fdef, 'dt1');
		parser.staticParse(algoFormulas.hadamard, 'dt2');
		parser.staticParse(algoFormulas.hexample1, 'dt3');
		parser.staticParse(algoFormulas.hexample2, 'dt4');
		parser.staticParse(algoFormulas.pipeline, 'dt5');
		parser.staticParse(algoFormulas.state1, 'dt_state1');
		parser.staticParse(algoFormulas.state0, 'dt_state2');
		parser.staticParse(algoFormulas.state2, 'dt_state3');
		parser.staticParse(algoFormulas.state3, 'dt_state4');
		parser.staticParse(algoFormulas.state4, 'dt_state5');
		parser.staticParse(algoFormulas.state5, 'dt_state6');

		parser.staticParse(algoFormulas.gg1, 'gg1');
		parser.staticParse(algoFormulas.gg2, 'gg2');
		parser.staticParse(algoFormulas.gg3, 'gg3');
		parser.staticParse(algoFormulas.gg4, 'gg4');
		parser.staticParse(algoFormulas.gg5, 'gg5');
		parser.staticParse(algoFormulas.gg6, 'gg6');
		parser.staticParse(algoFormulas.gg7, 'gg7');
		parser.staticParse(algoFormulas.gg8, 'gg8');
		parser.staticParse(algoFormulas.gg9, 'gg9');
		parser.staticParse(algoFormulas.gg10, 'gg10');
		parser.staticParse(algoFormulas.gg11, 'gg11');

		parser.staticParse(algoFormulas.ini1, 'ini1');
		parser.staticParse(algoFormulas.ini2, 'ini2');
		parser.staticParse(algoFormulas.ini3, 'ini3');
		parser.staticParse(algoFormulas.ini4, 'ini4');
		parser.staticParse(algoFormulas.ini5, 'ini5');
		parser.staticParse(algoFormulas.ini6, 'ini6');
		parser.staticParse(algoFormulas.ini7, 'ini7');
		parser.staticParse(algoFormulas.ini8, 'ini8');
		parser.staticParse(algoFormulas.ini9, 'ini9');
		parser.staticParse(algoFormulas.ini10, 'ini10');

		parser.staticParse(algoFormulas.system, 'hhl1');
		parser.staticParse(algoFormulas.system2, 'hhl2');
		parser.staticParse(algoFormulas.hhl3, 'hhl3');
		parser.staticParse(algoFormulas.tensor1, 'tensor1');
		parser.staticParse(algoFormulas.tensor2, 'tensor2');
		parser.staticParse(algoFormulas.adiFormula1, 'adiFormula1');
		parser.staticParse(algoFormulas.adiFormula2, 'adiFormula2');
		parser.staticParse(algoFormulas.adiFormula3, 'adiFormula3');
		parser.staticParse(algoFormulas.adiFormula4, 'adiFormula4');
		parser.staticParse(algoFormulas.adiFormula5, 'adiFormula5');
		parser.staticParse(algoFormulas.adiFormula6, 'adiFormula6');
		parser.staticParse(algoFormulas.adiFormula7, 'adiFormula7');
		parser.staticParse(algoFormulas.adiFormula8, 'adiFormula8');
		parser.staticParse(algoFormulas.adiFormula9, 'adiFormula9');
		parser.staticParse(algoFormulas.adiFormula10, 'adiFormula10');
		parser.staticParse(algoFormulas.adiFormula11, 'adiFormula11');
		parser.staticParse(algoFormulas.adiFormula12, 'adiFormula12');
		parser.staticParse(algoFormulas.adiFormula13, 'adiFormula13');
		parser.staticParse(algoFormulas.adiFormula14, 'adiFormula14');
		parser.staticParse(algoFormulas.adiFormula15, 'adiFormula15');		
		parser.staticParse(algoFormulas.adiFormula16, 'adiFormula16');
		parser.staticParse(algoFormulas.adiFormula16, 'adiFormula17');
		parser.staticParse(algoFormulas.adiFormula18, 'adiFormula18');
		parser.staticParse(algoFormulas.adiFormula19, 'adiFormula19');	

		parser.staticParse(algoFormulas.hhl4,"hhl4");			
		parser.staticParse(algoFormulas.hhl5,"hhl5");			
		parser.staticParse(algoFormulas.hhl6,"hhl6");			
		parser.staticParse(algoFormulas.hhl7,"hhl7");			
		parser.staticParse(algoFormulas.hhl7,"hhl7p");			
		parser.staticParse(algoFormulas.hhl8,"hhl8");			
		parser.staticParse(algoFormulas.hhl9,"hhl9");
		parser.staticParse(algoFormulas.hermite1, "hermite1");			
		parser.staticParse(algoFormulas.invertible, "invertible");
		parser.staticParse(algoFormulas.lambdas, "lambdas");
		parser.staticParse(algoFormulas.inverse, "inverse");
		parser.staticParse(algoFormulas.inverse2, "inverse2");

		parser.staticParse(algoFormulas.rr1, "rr1");
		parser.staticParse(algoFormulas.rr2, "rr2");
		parser.staticParse(algoFormulas.rr3, "rr3");
		parser.staticParse(algoFormulas.rr4, "rr4");
		parser.staticParse(algoFormulas.rr5, "rr5");
		parser.staticParse(algoFormulas.rr6, "rr6");
		parser.staticParse(algoFormulas.rr7, "rr7");
		parser.staticParse(algoFormulas.rr7, "rr7b");
		parser.staticParse(algoFormulas.rr8, "rr8");
		parser.staticParse(algoFormulas.rr9, "rr9");
		parser.staticParse(algoFormulas.rr0, "rr0");
		parser.staticParse(algoFormulas.mes, "mes");
	</script>
	</div> 
</body>

</html>
 
